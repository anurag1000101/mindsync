{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import pickle\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from transformers import BartTokenizer\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset\n",
    "from datasets import load_metric\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('C:/Users/Anurag/Desktop/EEG2text/src')\n",
    "from dataclasses import dataclass\n",
    "from torch.nn import BCEWithLogitsLoss, CrossEntropyLoss, MSELoss\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.multiprocessing as mp\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.distributed import init_process_group, destroy_process_group\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import optim\n",
    "import logging\n",
    "from datetime import datetime\n",
    "from config import ModelConfig_wordlevel\n",
    "from models import *\n",
    "from transformers import BartTokenizer\n",
    "import pickle\n",
    "from common.utils.data import *\n",
    "import warnings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZuCo_dataset(Dataset):\n",
    "    def __init__(self, input_dataset_dicts, phase, tokenizer, subject = 'ALL', eeg_type = 'GD', bands = ['_t1','_t2','_a1','_a2','_b1','_b2','_g1','_g2'], setting = 'unique_sent', is_add_CLS_token = False, max_len : int= None):\n",
    "        self.inputs = []\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "        if not isinstance(input_dataset_dicts,list):\n",
    "            input_dataset_dicts = [input_dataset_dicts]\n",
    "        print(f'[INFO]loading {len(input_dataset_dicts)} task datasets')\n",
    "        \n",
    "        for input_dataset_dict in input_dataset_dicts:\n",
    "            if subject == 'ALL':\n",
    "                subjects = list(input_dataset_dict.keys())\n",
    "                print('[INFO]using subjects: ', subjects)\n",
    "            else:\n",
    "                subjects = [subject]\n",
    "            \n",
    "            total_num_sentence = len(input_dataset_dict[subjects[0]])\n",
    "            \n",
    "            train_divider = int(0.8*total_num_sentence)\n",
    "            dev_divider = train_divider + int(0.1*total_num_sentence)\n",
    "            \n",
    "            print(f'train divider = {train_divider}')\n",
    "            print(f'dev divider = {dev_divider}')\n",
    "\n",
    "            if setting == 'unique_sent':\n",
    "                # take first 80% as trainset, 10% as dev and 10% as test\n",
    "                if phase == 'train':\n",
    "                    print('[INFO]initializing a train set...')\n",
    "                    for key in subjects:\n",
    "                        for i in range(train_divider):\n",
    "                            input_sample = get_input_sample(input_dataset_dict[key][i],self.tokenizer,eeg_type,bands = bands, add_CLS_token = is_add_CLS_token)\n",
    "                            if input_sample is not None:\n",
    "                                self.inputs.append(input_sample)\n",
    "                elif phase == 'dev':\n",
    "                    print('[INFO]initializing a dev set...')\n",
    "                    for key in subjects:\n",
    "                        for i in range(train_divider,dev_divider):\n",
    "                            input_sample = get_input_sample(input_dataset_dict[key][i],self.tokenizer,eeg_type,bands = bands, add_CLS_token = is_add_CLS_token)\n",
    "                            if input_sample is not None:\n",
    "                                self.inputs.append(input_sample)\n",
    "                elif phase == 'test':\n",
    "                    print('[INFO]initializing a test set...')\n",
    "                    for key in subjects:\n",
    "                        for i in range(dev_divider,total_num_sentence):\n",
    "                            input_sample = get_input_sample(input_dataset_dict[key][i],self.tokenizer,eeg_type,bands = bands, add_CLS_token = is_add_CLS_token)\n",
    "                            if input_sample is not None:\n",
    "                                self.inputs.append(input_sample)\n",
    "            elif setting == 'unique_subj':\n",
    "                print('WARNING!!! only implemented for SR v1 dataset ')\n",
    "                # subject ['ZAB', 'ZDM', 'ZGW', 'ZJM', 'ZJN', 'ZJS', 'ZKB', 'ZKH', 'ZKW'] for train\n",
    "                # subject ['ZMG'] for dev\n",
    "                # subject ['ZPH'] for test\n",
    "                if phase == 'train':\n",
    "                    print(f'[INFO]initializing a train set using {setting} setting...')\n",
    "                    for i in range(total_num_sentence):\n",
    "                        for key in ['ZAB', 'ZDM', 'ZGW', 'ZJM', 'ZJN', 'ZJS', 'ZKB', 'ZKH','ZKW']:\n",
    "                            input_sample = get_input_sample(input_dataset_dict[key][i],self.tokenizer,eeg_type,bands = bands, add_CLS_token = is_add_CLS_token)\n",
    "                            if input_sample is not None:\n",
    "                                self.inputs.append(input_sample)\n",
    "                if phase == 'dev':\n",
    "                    print(f'[INFO]initializing a dev set using {setting} setting...')\n",
    "                    for i in range(total_num_sentence):\n",
    "                        for key in ['ZMG']:\n",
    "                            input_sample = get_input_sample(input_dataset_dict[key][i],self.tokenizer,eeg_type,bands = bands, add_CLS_token = is_add_CLS_token)\n",
    "                            if input_sample is not None:\n",
    "                                self.inputs.append(input_sample)\n",
    "                if phase == 'test':\n",
    "                    print(f'[INFO]initializing a test set using {setting} setting...')\n",
    "                    for i in range(total_num_sentence):\n",
    "                        for key in ['ZPH']:\n",
    "                            input_sample = get_input_sample(input_dataset_dict[key][i],self.tokenizer,eeg_type,bands = bands, add_CLS_token = is_add_CLS_token)\n",
    "                            if input_sample is not None:\n",
    "                                self.inputs.append(input_sample)\n",
    "            # print('++ adding task to dataset, now we have:', len(self.inputs))\n",
    "\n",
    "        # print('[INFO]input tensor size:', self.inputs[0]['input_embeddings'].size())\n",
    "        print()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_sample = self.inputs[idx]\n",
    "        \n",
    "        raw_eeg = input_sample['raw_eeg']\n",
    "        if self.max_len is not None:\n",
    "            # Truncate or pad raw_eeg array\n",
    "            if raw_eeg.shape[1] > self.max_len:\n",
    "                raw_eeg = raw_eeg[:, :self.max_len]\n",
    "            elif raw_eeg.shape[1] < self.max_len:\n",
    "                pad_width = ((0, 0), (0, self.max_len - raw_eeg.shape[1]))\n",
    "                raw_eeg = np.pad(raw_eeg, pad_width, mode='constant', constant_values=0)\n",
    "        \n",
    "        # return (\n",
    "        #     raw_eeg,\n",
    "        #     input_sample['target_string'],\n",
    "        #     input_sample['target_ids'], \n",
    "        #     input_sample['target_mask'],  \n",
    "        # )\n",
    "        return (\n",
    "            raw_eeg,\n",
    "            input_sample['target_string'],\n",
    "            input_sample['target_ids'], \n",
    "            input_sample['target_mask'],  \n",
    "            input_sample['input_embeddings'], # new\n",
    "            input_sample['seq_len'], # new\n",
    "            input_sample['input_attn_mask'], \n",
    "            input_sample['input_attn_mask_invert'],\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BartTokenizer.from_pretrained('facebook/bart-large')\n",
    "dataset_setting = 'unique_sent'\n",
    "subject_choice = 'ALL'\n",
    "eeg_type_choice = 'GD'\n",
    "bands_choice = ['_t1','_t2','_a1','_a2','_b1','_b2','_g1','_g2'] \n",
    "\n",
    "config=ModelConfig_wordlevel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating whole_dataset_dicts...\n",
      "whole_dataset_dicts created\n"
     ]
    }
   ],
   "source": [
    "print('Creating whole_dataset_dicts...')\n",
    "whole_dataset_dicts = []\n",
    "dataset_path_task1 = '/nlsasfs/home/nltm-st/sujitk/temp/eeg2text/datasets/pickle/task1-SR-1.0/task1-SR-1.0-dataset.pickle' \n",
    "with open(dataset_path_task1, 'rb') as handle:\n",
    "    whole_dataset_dicts.append(pickle.load(handle))\n",
    "print('whole_dataset_dicts created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataloader(dataset: Dataset):\n",
    "    return DataLoader(\n",
    "        dataset,\n",
    "        drop_last=False,\n",
    "        batch_size=1,\n",
    "        shuffle=False,\n",
    "        # sampler=DistributedSampler(dataset, shuffle=True)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for t in ['train','dev','test']:\n",
    "#     dset = ZuCo_dataset(whole_dataset_dicts, t, tokenizer, subject = subject_choice, eeg_type = eeg_type_choice, bands = bands_choice, setting = dataset_setting, max_len=config.time_len)\n",
    "#     dl = prepare_dataloader(dset)\n",
    "#     batch_iterator = tqdm(dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]loading 1 task datasets\n",
      "[INFO]using subjects:  ['ZAB', 'ZDM', 'ZDN', 'ZGW', 'ZJM', 'ZJN', 'ZJS', 'ZKB', 'ZKH', 'ZKW', 'ZMG', 'ZPH']\n",
      "train divider = 320\n",
      "dev divider = 360\n",
      "[INFO]initializing a train set...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dset = ZuCo_dataset(whole_dataset_dicts, 'train', tokenizer, subject = subject_choice, eeg_type = eeg_type_choice, bands = bands_choice, setting = dataset_setting, max_len=config.time_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3609 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "dl = prepare_dataloader(dset)\n",
    "batch_iterator = tqdm(dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[True, True]])\n",
      "tensor([[True, True]])\n",
      "tensor([[True, True]])\n",
      "tensor([[True, True]])\n",
      "tensor([[True, True]])\n",
      "tensor([[True, True]])\n",
      "tensor([[True, True]])\n",
      "tensor([[True, True]])\n",
      "tensor([[True, True]])\n",
      "tensor([[True, True]])\n",
      "tensor([[True, True]])\n",
      "tensor([[True, True]])\n",
      "tensor([[True, True]])\n",
      "tensor([[True, True]])\n",
      "tensor([[True, True]])\n",
      "tensor([[True, True]])\n",
      "tensor([[True, True]])\n",
      "tensor([[True, True]])\n",
      "tensor([[True, True]])\n",
      "tensor([[True, True]])\n",
      "tensor([[True, True]])\n",
      "tensor([[True, True]])\n",
      "tensor([[True, True]])\n",
      "tensor([[True, True]])\n",
      "tensor([[True, True]])\n",
      "tensor([[True, True]])\n",
      "tensor([[True, True]])\n",
      "tensor([[True, True]])\n",
      "tensor([[True, True]])\n",
      "tensor([[True, True]])\n",
      "tensor([[True, True]])\n",
      "tensor([[True, True]])\n",
      "tensor([[True, True]])\n",
      "tensor([[True, True]])\n",
      "tensor([[True, True]])\n",
      "tensor([[True, True]])\n",
      "tensor([[True, True]])\n",
      "tensor([[True, True]])\n",
      "tensor([[True, True]])\n",
      "tensor([[True, True]])\n",
      "tensor([[True, True]])\n",
      "tensor([[True, True]])\n",
      "tensor([[True, True]])\n",
      "tensor([[True, True]])\n",
      "tensor([[True, True]])\n",
      "tensor([[True, True]])\n",
      "tensor([[True, True]])\n",
      "tensor([[True, True]])\n",
      "tensor([[True, True]])\n"
     ]
    }
   ],
   "source": [
    "i=1\n",
    "for raw_eeg, target_string, target_ids, target_mask, word_level_embed, orig_seq_len, input_attn_mask, input_attn_mask_invert  in batch_iterator:\n",
    "    raw_eeg = raw_eeg.to(torch.float32) #.to(self.gpu_id)\n",
    "    # print(f'raw_eeg.shape: {raw_eeg.shape}, raw_eeg: {raw_eeg}')\n",
    "    # print(torch.isnan(raw_eeg).any(), end='\\n\\n')\n",
    "    tr=torch.isnan(raw_eeg)\n",
    "    print(torch.nonzero(torch.sum(tr,dim=2))==torch.tensor([[  0, 104]]))\n",
    "    \n",
    "    i+=1\n",
    "    if(i>=50):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_count: 3609, last_channel_nan_count: tensor([[3609, 3609]])\n"
     ]
    }
   ],
   "source": [
    "total_count=len(dset)\n",
    "last_channel_nan_count=0\n",
    "for raw_eeg, target_string, target_ids, target_mask, word_level_embed, orig_seq_len, input_attn_mask, input_attn_mask_invert  in batch_iterator:\n",
    "    raw_eeg = raw_eeg.to(torch.float32) #.to(self.gpu_id)\n",
    "    # print(f'raw_eeg.shape: {raw_eeg.shape}, raw_eeg: {raw_eeg}')\n",
    "    # print(torch.isnan(raw_eeg).any(), end='\\n\\n')\n",
    "    tr=torch.isnan(raw_eeg)\n",
    "    last_channel_nan=(torch.nonzero(torch.sum(tr,dim=2))==torch.tensor([[  0, 104]]))\n",
    "    last_channel_nan_count+=last_channel_nan\n",
    "    i+=1\n",
    "\n",
    "print(f'total_count: {total_count}, last_channel_nan_count: {last_channel_nan_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_channel_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         ...,\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [ True,  True,  True,  ..., False, False, False]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0, 3341]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trs=torch.sum(tr,dim=2)\n",
    "trs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0, 104]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nonzero(trs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3609"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(True), tensor(True), tensor(True), tensor(True), tensor(True), tensor(True), tensor(True), tensor(True), tensor(True), tensor(True), \n",
      "tensor(True), tensor(True), tensor(True), tensor(True), tensor(True), tensor(True), tensor(True), tensor(True), tensor(True), tensor(True), \n",
      "tensor(True), tensor(True), tensor(True), tensor(True), tensor(True), tensor(True), tensor(True), tensor(True), tensor(True), tensor(True), \n",
      "tensor(True), tensor(True), tensor(True), tensor(True), tensor(True), tensor(True), tensor(True), tensor(True), tensor(True), tensor(True), \n",
      "tensor(True), tensor(True), tensor(True), tensor(True), tensor(True), tensor(True), tensor(True), tensor(True), tensor(True), "
     ]
    }
   ],
   "source": [
    "i=1\n",
    "for raw_eeg, target_string, target_ids, target_mask, word_level_embed, orig_seq_len, input_attn_mask, input_attn_mask_invert  in batch_iterator:\n",
    "    raw_eeg = raw_eeg.to(torch.float32) #.to(self.gpu_id)\n",
    "    # print(f'raw_eeg.shape: {raw_eeg.shape}, raw_eeg: {raw_eeg}')\n",
    "    print(torch.isnan(raw_eeg).any(), end=', ')\n",
    "    if(i%10==0): print()\n",
    "    i+=1\n",
    "    if(i>=50):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating whole_dataset_dicts...\n",
      "whole_dataset_dicts created\n"
     ]
    }
   ],
   "source": [
    "print('Creating whole_dataset_dicts...')\n",
    "zuco2 = []\n",
    "dataset_path_task2_v2 = '/nlsasfs/home/nltm-st/sujitk/temp/eeg2text/datasets/pickle/task2-NR-2.0/task2-NR-2.0-dataset.pickle' \n",
    "with open(dataset_path_task2_v2, 'rb') as handle:\n",
    "    zuco2.append(pickle.load(handle))\n",
    "print('whole_dataset_dicts created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]loading 1 task datasets\n",
      "[INFO]using subjects:  ['YSD', 'YDR', 'YRK', 'YFS', 'YAG', 'YIS', 'YLS', 'YRH', 'YHS', 'YMS', 'YSL', 'YDG', 'YFR', 'YRP', 'YTL', 'YAC', 'YAK', 'YMD']\n",
      "train divider = 279\n",
      "dev divider = 313\n",
      "[INFO]initializing a dev set...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dset2 = ZuCo_dataset(zuco2, 'dev', tokenizer, subject = subject_choice, eeg_type = eeg_type_choice, bands = bands_choice, setting = dataset_setting, max_len=config.time_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/522 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "dl2 = prepare_dataloader(dset2)\n",
    "batch_iterator2 = tqdm(dl2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/522 [00:04<37:01,  4.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(False), "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 11/522 [00:04<02:02,  4.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(False), tensor(False), tensor(False), tensor(False), tensor(False), tensor(False), tensor(False), tensor(False), tensor(False), \n",
      "tensor(False), tensor(False), tensor(False), tensor(False), tensor(False), tensor(False), tensor(False), "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 18/522 [00:04<01:04,  7.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(False), tensor(False), tensor(False), \n",
      "tensor(False), tensor(False), tensor(False), tensor(False)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 24/522 [00:05<00:47, 10.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ", "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 29/522 [00:05<00:50,  9.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(False), tensor(False), tensor(False), tensor(False), tensor(False), tensor(False), \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 40/522 [00:05<00:27, 17.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(False), tensor(False), tensor(False), tensor(False), tensor(False), tensor(False), tensor(False), tensor(False), tensor(False), tensor(False), \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 48/522 [00:06<01:00,  7.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(False), tensor(False), tensor(False), tensor(False), tensor(False), tensor(False), tensor(False), tensor(False), tensor(False), "
     ]
    }
   ],
   "source": [
    "i=1\n",
    "for raw_eeg, target_string, target_ids, target_mask, word_level_embed, orig_seq_len, input_attn_mask, input_attn_mask_invert  in batch_iterator2:\n",
    "    raw_eeg = raw_eeg.to(torch.float32) #.to(self.gpu_id)\n",
    "    # print(f'raw_eeg.shape: {raw_eeg.shape}, raw_eeg: {raw_eeg}')\n",
    "    print(torch.isnan(raw_eeg).any(), end=', ')\n",
    "    if(i%10==0): print()\n",
    "    i+=1\n",
    "    if(i>=50):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects = []\n",
    "with (open(\"NR-1.0\", \"rb\")) as openfile:\n",
    "    while True:\n",
    "        try:\n",
    "            objects.append(pickle.load(openfile))\n",
    "        except EOFError:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['ZAB', 'ZDM', 'ZDN', 'ZGW', 'ZJM', 'ZJN', 'ZJS', 'ZKB', 'ZKH', 'ZKW', 'ZMG', 'ZPH'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Different subjects\n",
    "objects[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['content', 'sentence_level_EEG', 'raw_eeg', 'word', 'word_tokens_has_fixation', 'word_tokens_with_mask', 'word_tokens_all'])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objects[0]['ZAB'][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects[0]['ZAB'][0]['sentence_level_EEG'] # each of 8 bands (frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(objects[0]['ZAB'][0]['sentence_level_EEG']['mean_a1'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
